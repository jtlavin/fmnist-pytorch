{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f645ea4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e527a2",
   "metadata": {},
   "source": [
    "# Load & Visualize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "770680b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4447b357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78ce2d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28]) 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x12a14cf50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Choose a random image\n",
    "img, label = training_data[torch.randint(len(training_data), size=(1,)).item()]\n",
    "print(img.shape, label)\n",
    "\n",
    "# Map label to name\n",
    "labels_map = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}\n",
    "\n",
    "# Plot image\n",
    "plt.title(labels_map[label])\n",
    "plt.imshow(img.squeeze(), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a870a125",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4217a9",
   "metadata": {},
   "source": [
    "# Build a Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fc2d526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "# Choose device for trainning, use some accelerator if available else use CPU\n",
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90206764",
   "metadata": {},
   "source": [
    "MPS is available and its Apples's equivalent of NVIDIA's CUDA. It allows pytorch to run on Apple's M series chips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6ad2595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define neural network\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b9dcdfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d4e139",
   "metadata": {},
   "source": [
    "# Training Loop\n",
    "\n",
    "We need:\n",
    "1. Data -> comes from dataloader\n",
    "2. Model -> structure defined by us\n",
    "3. Loss Function -> Choose a loss function, for example CrossEntropyLoss\n",
    "4. Optimizer -> Choose an optimizer, for example SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2b419bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-2\n",
    "batch_size = 64\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ccf66a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.train()\n",
    "    for batch, (X,y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f'loss: {loss:>7f}  [{current:>5d}/{size:>5d}]')\n",
    "    \n",
    "# Test Loop\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe38ba86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.974848  [    0/60000]\n",
      "loss: 0.973072  [ 6400/60000]\n",
      "loss: 0.943131  [12800/60000]\n",
      "loss: 0.751179  [19200/60000]\n",
      "loss: 0.916347  [25600/60000]\n",
      "loss: 0.880011  [32000/60000]\n",
      "loss: 0.716239  [38400/60000]\n",
      "loss: 0.757687  [44800/60000]\n",
      "loss: 0.680925  [51200/60000]\n",
      "loss: 0.585602  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.9%, Avg loss: 0.696563 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.606556  [    0/60000]\n",
      "loss: 0.730592  [ 6400/60000]\n",
      "loss: 0.415060  [12800/60000]\n",
      "loss: 0.616578  [19200/60000]\n",
      "loss: 0.593869  [25600/60000]\n",
      "loss: 0.564062  [32000/60000]\n",
      "loss: 0.506796  [38400/60000]\n",
      "loss: 0.518296  [44800/60000]\n",
      "loss: 0.545215  [51200/60000]\n",
      "loss: 0.456559  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.592177 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.466615  [    0/60000]\n",
      "loss: 0.538791  [ 6400/60000]\n",
      "loss: 0.503004  [12800/60000]\n",
      "loss: 0.668113  [19200/60000]\n",
      "loss: 0.379512  [25600/60000]\n",
      "loss: 0.744295  [32000/60000]\n",
      "loss: 0.445790  [38400/60000]\n",
      "loss: 0.510854  [44800/60000]\n",
      "loss: 0.417582  [51200/60000]\n",
      "loss: 0.476718  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.585569 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.476570  [    0/60000]\n",
      "loss: 0.615866  [ 6400/60000]\n",
      "loss: 0.678578  [12800/60000]\n",
      "loss: 0.537572  [19200/60000]\n",
      "loss: 0.455046  [25600/60000]\n",
      "loss: 0.534997  [32000/60000]\n",
      "loss: 0.399579  [38400/60000]\n",
      "loss: 0.481520  [44800/60000]\n",
      "loss: 0.693921  [51200/60000]\n",
      "loss: 0.512245  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.521897 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.461993  [    0/60000]\n",
      "loss: 0.480162  [ 6400/60000]\n",
      "loss: 0.314747  [12800/60000]\n",
      "loss: 0.445342  [19200/60000]\n",
      "loss: 0.426324  [25600/60000]\n",
      "loss: 0.432921  [32000/60000]\n",
      "loss: 0.441558  [38400/60000]\n",
      "loss: 0.474573  [44800/60000]\n",
      "loss: 0.426565  [51200/60000]\n",
      "loss: 0.578945  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.531664 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.724843  [    0/60000]\n",
      "loss: 0.402375  [ 6400/60000]\n",
      "loss: 0.578982  [12800/60000]\n",
      "loss: 0.552397  [19200/60000]\n",
      "loss: 0.461406  [25600/60000]\n",
      "loss: 0.523922  [32000/60000]\n",
      "loss: 0.326753  [38400/60000]\n",
      "loss: 0.621310  [44800/60000]\n",
      "loss: 0.439347  [51200/60000]\n",
      "loss: 0.515605  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.485964 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.689018  [    0/60000]\n",
      "loss: 0.476569  [ 6400/60000]\n",
      "loss: 0.336092  [12800/60000]\n",
      "loss: 0.597303  [19200/60000]\n",
      "loss: 0.381866  [25600/60000]\n",
      "loss: 0.410211  [32000/60000]\n",
      "loss: 0.489621  [38400/60000]\n",
      "loss: 0.551257  [44800/60000]\n",
      "loss: 0.471994  [51200/60000]\n",
      "loss: 0.511058  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.469335 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.315134  [    0/60000]\n",
      "loss: 0.624946  [ 6400/60000]\n",
      "loss: 0.430159  [12800/60000]\n",
      "loss: 0.476736  [19200/60000]\n",
      "loss: 0.341210  [25600/60000]\n",
      "loss: 0.449089  [32000/60000]\n",
      "loss: 0.486825  [38400/60000]\n",
      "loss: 0.435301  [44800/60000]\n",
      "loss: 0.335261  [51200/60000]\n",
      "loss: 0.583216  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.456502 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.378685  [    0/60000]\n",
      "loss: 0.389076  [ 6400/60000]\n",
      "loss: 0.327968  [12800/60000]\n",
      "loss: 0.379727  [19200/60000]\n",
      "loss: 0.358340  [25600/60000]\n",
      "loss: 0.416760  [32000/60000]\n",
      "loss: 0.460730  [38400/60000]\n",
      "loss: 0.744597  [44800/60000]\n",
      "loss: 0.311723  [51200/60000]\n",
      "loss: 0.357719  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.474910 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.457363  [    0/60000]\n",
      "loss: 0.544594  [ 6400/60000]\n",
      "loss: 0.356707  [12800/60000]\n",
      "loss: 0.380130  [19200/60000]\n",
      "loss: 0.368275  [25600/60000]\n",
      "loss: 0.345585  [32000/60000]\n",
      "loss: 0.331739  [38400/60000]\n",
      "loss: 0.447222  [44800/60000]\n",
      "loss: 0.384492  [51200/60000]\n",
      "loss: 0.305766  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.446051 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4c13ad",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a027a515",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"simple_configuration.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1250320",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a6bc5481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "961709d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = test_data[0][0], test_data[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "03c0e49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.unsqueeze(0).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "46970ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicción: Ankle Boot, Real: Ankle Boot\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): \n",
    "    pred = model(x)\n",
    "predicted_label = pred.argmax(1).item()\n",
    "\n",
    "actual_label = y\n",
    "print(f\"Predicción: {labels_map[predicted_label]}, Real: {labels_map[actual_label]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
